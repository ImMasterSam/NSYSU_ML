"""
åœ°é»åˆä½µå·¥å…· - æ ¹æ“šåº§æ¨™è‡ªå‹•åˆ†ç¾¤ï¼Œä¸¦ç”¢ç”Ÿå»ºè­°çš„åˆä½µè¦å‰‡
"""

import pandas as pd
import numpy as np
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.spatial.distance import pdist

# è¼‰å…¥è³‡æ–™
df_coords = pd.read_csv('../../data_after_process/unique_locations.csv', encoding='utf-8-sig')
print(f"ğŸ“ åŸå§‹åœ°é»æ•¸: {len(df_coords)}")
print("\nåŸå§‹åœ°é»åˆ—è¡¨:")
for i, row in df_coords.iterrows():
    print(f"  {i+1}. {row['Location']}")

# è¨ˆç®— Haversine è·é›¢ (å…¬å°º)
def haversine(coord1, coord2):
    lat1, lon1 = np.radians(coord1)
    lat2, lon2 = np.radians(coord2)
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    return 6371000 * 2 * np.arcsin(np.sqrt(a))

# æº–å‚™åº§æ¨™çŸ©é™£
coords = df_coords[['Latitude', 'Longitude']].values
locations = df_coords['Location'].tolist()

# è¨ˆç®—è·é›¢çŸ©é™£
n = len(coords)
dist_matrix = np.zeros((n, n))
for i in range(n):
    for j in range(i+1, n):
        d = haversine(coords[i], coords[j])
        dist_matrix[i, j] = d
        dist_matrix[j, i] = d

print(f"\nğŸ“ è·é›¢ç¯„åœ: {dist_matrix[dist_matrix > 0].min():.0f}m ~ {dist_matrix.max():.0f}m")

# ä½¿ç”¨éšå±¤å¼åˆ†ç¾¤ (Hierarchical Clustering)
# è¨­å®šä¸åŒçš„è·é›¢é–¾å€¼
thresholds = [50, 100, 150, 200]

print("\n" + "=" * 70)
print("ğŸ” è‡ªå‹•åˆ†ç¾¤å»ºè­° (æ ¹æ“šä¸åŒè·é›¢é–¾å€¼)")
print("=" * 70)

for threshold in thresholds:
    # ä½¿ç”¨ complete linkage (æœ€é è·é›¢)
    condensed_dist = pdist(coords, metric=lambda u, v: haversine(u, v))
    Z = linkage(condensed_dist, method='complete')
    clusters = fcluster(Z, t=threshold, criterion='distance')
    
    n_clusters = len(set(clusters))
    print(f"\nğŸ“¦ é–¾å€¼ {threshold}m â†’ {n_clusters} å€‹ç¾¤çµ„")
    
    # é¡¯ç¤ºæ¯å€‹ç¾¤çµ„
    cluster_dict = {}
    for loc, c in zip(locations, clusters):
        if c not in cluster_dict:
            cluster_dict[c] = []
        cluster_dict[c].append(loc)
    
    for c, locs in sorted(cluster_dict.items()):
        if len(locs) > 1:
            print(f"   ç¾¤çµ„ {c}: {', '.join(locs[:3])}{'...' if len(locs) > 3 else ''} ({len(locs)} å€‹)")

# ç”¢ç”Ÿ 100m é–¾å€¼çš„è©³ç´°åˆ†ç¾¤çµæœ
print("\n" + "=" * 70)
print("ğŸ“‹ å»ºè­°åˆä½µè¦å‰‡ (100m é–¾å€¼ï¼Œä½ å¯ä»¥æ‰‹å‹•èª¿æ•´)")
print("=" * 70)

condensed_dist = pdist(coords, metric=lambda u, v: haversine(u, v))
Z = linkage(condensed_dist, method='complete')
clusters = fcluster(Z, t=100, criterion='distance')

# å»ºç«‹åˆ†ç¾¤çµæœ
cluster_dict = {}
for loc, c in zip(locations, clusters):
    if c not in cluster_dict:
        cluster_dict[c] = []
    cluster_dict[c].append(loc)

# ç”¢ç”Ÿ CSV æ ¼å¼çš„è¦å‰‡
rules = []
for c, locs in sorted(cluster_dict.items()):
    # ç”¨ç¬¬ä¸€å€‹åœ°é»åç¨±ä½œç‚ºå€åŸŸåç¨±ï¼Œæˆ–è€…ä½ å¯ä»¥è‡ªå·±å‘½å
    zone_name = locs[0] if len(locs) == 1 else f"Zone_{c}"
    for loc in locs:
        rules.append({
            'Original_Location': loc,
            'Zone_ID': c,
            'Zone_Name': zone_name,
            'Locations_in_Zone': len(locs)
        })

df_rules = pd.DataFrame(rules)
df_rules.to_csv('location_rules.csv', index=False, encoding='utf-8-sig')

print("\nâœ… å·²ç”¢ç”Ÿ location_rules.csvï¼Œå…§å®¹å¦‚ä¸‹ï¼š")
print(df_rules.to_string())

print("\n" + "=" * 70)
print("ğŸ“ ä¸‹ä¸€æ­¥")
print("=" * 70)
print("""
1. æ‰“é–‹ location_rules.csv
2. ä¿®æ”¹ Zone_Name æ¬„ä½ï¼Œçµ¦æ¯å€‹å€åŸŸå–ä¸€å€‹æœ‰æ„ç¾©çš„åç¨±
3. ä¾‹å¦‚ï¼š
   - ã€Œç†å­¸é™¢ã€ã€ã€Œå·¥å­¸é™¢ã€ã€ã€Œç®¡é™¢ã€
   - ã€Œè¡Œæ”¿å¤§æ¨“å€ã€ã€ã€Œé«”è‚²é¤¨å€ã€
   - ã€Œç¬¬ä¸€åœè»Šå ´ã€ã€ã€Œç¬¬äºŒåœè»Šå ´ã€

4. å¦‚æœä½ è¦ºå¾—æŸäº›åœ°é»ä¸æ‡‰è©²åˆä½µï¼Œå¯ä»¥çµ¦å®ƒç¨ç«‹çš„ Zone_ID

5. å®Œæˆå¾ŒåŸ·è¡Œ violation_network_v3_zone.py ä¾†è¨“ç·´å€åŸŸæ¨¡å‹
""")
